{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize time series data\n",
    "from pandas import Series\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import dateparser\n",
    "\n",
    "path = 'data/talkingdata-adtracking-fraud-detection/'\n",
    "train_df = pd.read_csv(path + 'train_sample.csv') \n",
    "\n",
    "\n",
    "def standarize_date(series):\n",
    "    return series.apply(lambda x: str(dateparser.parse(x, settings={'DATE_ORDER': 'YMD'}))[:10])\n",
    "\n",
    "train_df['click_time_date'] =  standarize_date(train_df['click_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2017-11-07\n",
       "1        2017-11-07\n",
       "2        2017-11-07\n",
       "3        2017-11-07\n",
       "4        2017-11-09\n",
       "5        2017-11-09\n",
       "6        2017-11-09\n",
       "7        2017-11-07\n",
       "8        2017-11-08\n",
       "9        2017-11-08\n",
       "10       2017-11-08\n",
       "11       2017-11-07\n",
       "12       2017-11-09\n",
       "13       2017-11-08\n",
       "14       2017-11-07\n",
       "15       2017-11-08\n",
       "16       2017-11-09\n",
       "17       2017-11-09\n",
       "18       2017-11-06\n",
       "19       2017-11-06\n",
       "20       2017-11-09\n",
       "21       2017-11-08\n",
       "22       2017-11-08\n",
       "23       2017-11-07\n",
       "24       2017-11-07\n",
       "25       2017-11-07\n",
       "26       2017-11-07\n",
       "27       2017-11-07\n",
       "28       2017-11-07\n",
       "29       2017-11-07\n",
       "            ...    \n",
       "99970    2017-11-09\n",
       "99971    2017-11-08\n",
       "99972    2017-11-07\n",
       "99973    2017-11-09\n",
       "99974    2017-11-08\n",
       "99975    2017-11-09\n",
       "99976    2017-11-07\n",
       "99977    2017-11-09\n",
       "99978    2017-11-09\n",
       "99979    2017-11-09\n",
       "99980    2017-11-08\n",
       "99981    2017-11-09\n",
       "99982    2017-11-09\n",
       "99983    2017-11-07\n",
       "99984    2017-11-07\n",
       "99985    2017-11-09\n",
       "99986    2017-11-07\n",
       "99987    2017-11-08\n",
       "99988    2017-11-09\n",
       "99989    2017-11-07\n",
       "99990    2017-11-09\n",
       "99991    2017-11-09\n",
       "99992    2017-11-07\n",
       "99993    2017-11-09\n",
       "99994    2017-11-07\n",
       "99995    2017-11-09\n",
       "99996    2017-11-07\n",
       "99997    2017-11-08\n",
       "99998    2017-11-08\n",
       "99999    2017-11-07\n",
       "Name: click_time_date, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['click_time_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-11-08    34035\n",
       "2017-11-07    32393\n",
       "2017-11-09    28561\n",
       "2017-11-06     5011\n",
       "Name: click_time_date, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.click_time_date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '0        2' does not match format '%y %m %d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b8d8135758ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_df_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'click_time_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtrain_df_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'click_time_scaled.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'false'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b8d8135758ff>\u001b[0m in \u001b[0;36mnormalize_date\u001b[0;34m(series)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     values = values.reshape(len(values), 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%y %m %d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#scaler.fit(values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%y %m %d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#scaler.transform(values) #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alaa/anaconda2/lib/python2.7/_strptime.pyc\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0;32m--> 332\u001b[0;31m                          (data_string, format))\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         raise ValueError(\"unconverted data remains: %s\" %\n",
      "\u001b[0;31mValueError\u001b[0m: time data '0        2' does not match format '%y %m %d'"
     ]
    }
   ],
   "source": [
    "def normalize_date(series):\n",
    "    \"\"\"\n",
    "    A function used to normalize click_time \n",
    "    column data using Minmax scaler/ Standardscaler\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "#     values = series.values\n",
    "#     values = values.reshape(len(values), 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(datetime.strptime(series[:10], '%y %m %d'))  #scaler.fit(values)\n",
    "    normalized = scaler.transform(datetime.strptime(series[:10], '%y %m %d')) #scaler.transform(values) #\n",
    "    return normalized\n",
    "\n",
    "train_df_new = pd.DataFrame(normalize_date(train_df['click_time_date']))\n",
    "train_df_new.to_csv('click_time_scaled.csv', index='false')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # train_df = pd.read_csv(path + 'train_sample.csv')\n",
    "# # prepare data for standardization\n",
    "# values = series.values\n",
    "# values = values.reshape((len(values), 1))\n",
    "# # train the standardization\n",
    "# scaler = StandardScaler()\n",
    "# scaler = scaler.fit(values)\n",
    "# print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n",
    "# # standardization the dataset and print the first 5 rows\n",
    "# normalized = scaler.transform(values)\n",
    "# for i in range(5):\n",
    "# \tprint(normalized[i])\n",
    "# # inverse transform and print the first 5 rows\n",
    "# inversed = scaler.inverse_transform(normalized)\n",
    "# for i in range(5):\n",
    "# \tprint(inversed[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alaa/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.AdagradOptimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
